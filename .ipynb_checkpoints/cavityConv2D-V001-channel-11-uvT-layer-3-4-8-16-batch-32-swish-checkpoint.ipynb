{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport torch\\nimport pickle\\nimport os\\nimport skimage.io as io\\nimport skimage.transform as trans\\n\\nfrom functions import *\\nfrom torch.utils.data import TensorDataset\\n\\nimport os\\nimport json\\nimport torch\\nimport pickle\\nfrom train_functions import *\\nfrom functions import *\\nimport torch.optim as optim#hf = h5py.File('cavity_data_172_channel1_SDF.h5', 'r')\\n\\nfrom torch.utils.data import TensorDataset\\nfrom Models.UNetEx import UNetEx\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.ops import nn\n",
    "#from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "#from keras import backend as keras\n",
    "\"\"\"\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "from functions import *\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from train_functions import *\n",
    "from functions import *\n",
    "import torch.optim as optim#hf = h5py.File('cavity_data_172_channel1_SDF.h5', 'r')\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from Models.UNetEx import UNetEx\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function is tested using total_gen_loss= tf.constant(0.) and  tf.constant(1.)\n",
    "#from tensorflow.keras import backend\n",
    "def loss_function_generator(y_pred, y_true):\n",
    "\n",
    "    total_gen_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 64, 64, 11)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    2208        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    1608        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   3216        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   6416        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   12832       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   25632       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 32)   25632       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 64)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 32)   51232       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   25632       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   12816       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 32)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 16)   12816       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 16)   6416        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 16)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    3208        up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 16)   0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    3208        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 3)    603         conv2d_13[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 193,475\n",
      "Trainable params: 193,475\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "filters = [8, 16, 32, 32]\n",
    "f1=4\n",
    "f2=8\n",
    "f3=16\n",
    "ks=(5, 5)\n",
    "channel_out = 3\n",
    "chIn=11\n",
    "input_size = (64,64,chIn)\n",
    "inputs = Input(input_size)\n",
    "\n",
    "initializer = tf.random_normal_initializer(0., 0.02)\n",
    "kernel_initializer_N=initializer\n",
    "#kernel_initializer_N='he_normal'\n",
    "#kernel_initializer_N='glorot_uniform'\n",
    "#initializer = random_normal_initializer(0., 0.02)\n",
    "#kernel_initializer_N='he_normal'\n",
    "#activation_N='tanh'\n",
    "#activation_N='relu'\n",
    "#activation_N='selu'\n",
    "#activation_N='elu'\n",
    "#activation_N='sigmoid'\n",
    "#activation_N='softplus'\n",
    "activation_N=tf.nn.swish\n",
    "\n",
    "model = keras.Sequential()\n",
    "conv1 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(inputs)\n",
    "conv1 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv1)\n",
    "pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = keras.layers.Conv2D(filters = f2, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(pool1)\n",
    "conv2 = keras.layers.Conv2D(filters = f2, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv2)\n",
    "pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "\n",
    "conv3 = keras.layers.Conv2D(filters = f3, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(pool2)\n",
    "conv4 = keras.layers.Conv2D(filters = f3, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv3)\n",
    "#pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "#conv4 = keras.layers.Conv2D(filters = f4, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(pool3)\n",
    "#conv5 = keras.layers.Conv2D(filters = f4, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv4)\n",
    "#drop4 = keras.layers.Dropout(0.5)(conv4)\n",
    "#pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "\n",
    "#conv5 = keras.layers.Conv2D(1024, 3, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(pool4)\n",
    "#conv5 = keras.layers.Conv2D(1024, 3, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv5)\n",
    "#drop5 = keras.layers.Dropout(0.5)(conv5)\n",
    "\n",
    "\n",
    "#up6 = keras.layers.Conv2D(256, 3, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(UpSampling2D(size = (2,2))(drop4))\n",
    "\n",
    "up6 = keras.layers.Conv2D(filters = f3, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv4)\n",
    "merge6 = keras.layers.concatenate([conv3,up6],axis=3)\n",
    "conv6 = keras.layers.Conv2D(filters = f3, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(merge6)\n",
    "conv6 = keras.layers.Conv2D(filters = f3, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv6)\n",
    "\n",
    "#merged_tensors = keras.layers.concatenate([ZeroPadding2D(((3,0),(4,0)))(x1),x2],axis=3)\n",
    "\n",
    "up7 = keras.layers.Conv2D(filters = f2, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = keras.layers.concatenate([conv2,up7],axis=3)\n",
    "#merge7 = keras.layers.concatenate([ZeroPadding2D(((1,0),(1,0)))(up7),conv3],axis=3)\n",
    "conv7 = keras.layers.Conv2D(filters = f2, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(merge7)\n",
    "conv7 = keras.layers.Conv2D(filters = f2, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv7)\n",
    "\n",
    "\n",
    "up8 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = keras.layers.concatenate([conv1,up8],axis=3)\n",
    "#merge8 = keras.layers.concatenate([ZeroPadding2D(((0,0),(1,0)))(up8),conv2],axis=3)\n",
    "conv8 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(merge8)\n",
    "#conv8 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv8)\n",
    "\n",
    "\n",
    "#up9 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(UpSampling2D(size = (2,2))(conv8))\n",
    "#merge9 = keras.layers.concatenate([conv1,up9],axis=3)\n",
    "#merge9 = keras.layers.concatenate([ZeroPadding2D(((0,0),(1,0)))(up9),conv1],axis=3)\n",
    "#conv9 = keras.layers.Conv2D(filters = f1, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(merge9)\n",
    "#conv9 = keras.layers.Conv2D(64, kernel_size= ks, 0.7666162252426147activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv9)\n",
    "#conv9 = keras.layers.Conv2D(2, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv9)\n",
    "#conv10 = keras.layers.Conv2D(3, kernel_size= ks, activation=activation_N,padding = 'same', kernel_initializer = kernel_initializer_N)(conv9)\n",
    "conv10 = keras.layers.Conv2D(channel_out, kernel_size= ks, padding = 'same', kernel_initializer = kernel_initializer_N)(conv8)\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = Model(inputs = inputs, outputs = conv10)\n",
    "#model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.compile(optimizer = Adam(lr = LR), loss = loss_function_generator, metrics = ['accuracy'])\n",
    "\n",
    "#model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=LR), loss = tf.keras.losses.MeanSquaredError(), metrics = ['accuracy'])\n",
    "\n",
    "#model.compile(optimizer = Adam(lr = LR), loss = tf.keras.losses.MeanSquaredError(), metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('cavity_data_916_shuffle_channel_11-uvT.h5', 'r')\n",
    "hf.keys()\n",
    "geometry_xy = hf.get('geometry_xy')\n",
    "data_xy = hf.get('data_xy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(916, 64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(916, 64, 64, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_xy=np.empty((916,64,64,5), float)\n",
    "#geometry_xy=np.empty((916,64,64,chIn), float)\n",
    "\n",
    "#data_xy[:,:,:,:]=data_xy1[:,:,:,:]\n",
    "#geometry_xy[:,:,:,:]=geometry_xy1[:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_xy=np.empty((590,64,64,channel_out), float)\n",
    "train_geometry_xy=np.empty((590,64,64,chIn), float)\n",
    "train_data_xy[0:590,:,:,:]=data_xy[0:590,:,:,0:channel_out]\n",
    "train_geometry_xy[0:590,:,:,:]=geometry_xy[0:590,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 64, 64, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_xy=np.empty((296,64,64,channel_out), float)\n",
    "test_geometry_xy=np.empty((296,64,64,chIn), float)\n",
    "test_data_xy[0:296,:,:,:]=data_xy[590:886,:,:,0:channel_out]\n",
    "test_geometry_xy[0:296,:,:,:]=geometry_xy[590:886,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 64, 64, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_xy=np.empty((30,64,64,channel_out), float)\n",
    "pre_geometry_xy=np.empty((30,64,64,chIn), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_xy[0:30,:,:,:]=data_xy[886:916,:,:,0:channel_out]\n",
    "pre_geometry_xy[0:30,:,:,:]=geometry_xy[886:916,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('./checkpoint-layer-3-8-16-32-batch-32-elu_0.9136608242988586', custom_objects={'loss_function_generator': loss_function_generator})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nearly_stopping = EarlyStopping(monitor='val_loss', patience=25)\\n\\nhistory = model.fit(\\n                    train_geometry_xy, train_data_xy, \\n                    epochs=400, batch_size=32, callbacks=[early_stopping],\\n                    validation_data=(test_geometry_xy, test_data_xy)\\n                    )\\n                    \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=25)\n",
    "\n",
    "history = model.fit(\n",
    "                    train_geometry_xy, train_data_xy, \n",
    "                    epochs=400, batch_size=32, callbacks=[early_stopping],\n",
    "                    validation_data=(test_geometry_xy, test_data_xy)\n",
    "                    )\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoint-layer-3-4-8-16-batch-32-swish_{val_accuracy}\",\n",
    "    #save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 6/19 [========>.....................] - ETA: 7s - loss: 0.2756 - accuracy: 0.6763"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-87a1770f7569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mtrain_geometry_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_xy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_geometry_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit(data_xy, geometry_xy, epochs=5, batch_size=64)\n",
    "#model.fit(geometry_xy, data_xy, epochs=500)\n",
    "history = model.fit(\n",
    "                    train_geometry_xy, train_data_xy, \n",
    "                    epochs=2500, batch_size=32, callbacks=[model_checkpoint_callback],\n",
    "                    validation_data=(test_geometry_xy, test_data_xy)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cavityConv2D-V001-channel-11-uvT-layer-3-4-8-16-batch-32-swish.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "print('Training loss = ',min(loss), \"Validation loss = \", min(val_loss))\n",
    "print('Training accuracy = ',max(acc), \"Validation accuracy = \", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loss =  0.5445457696914673 Validation loss =  0.5349123477935791\n",
    "#Training accuracy =  0.8572048544883728 Validation accuracy =  0.8608496189117432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hf = h5py.File('rectCavity_3_all_channel_data.h5', 'r')\n",
    "#hf.keys()\n",
    "#geometry_xy1 = hf.get('geometry_xy')\n",
    "#data_xy1 = hf.get('data_xy')\n",
    "\n",
    "# 0 : SDF\n",
    "# 1 : BC\n",
    "# 2 : cell_x\n",
    "# 3 : cell_y\n",
    "# 4 : Re\n",
    "# 5 : mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geometry_xy1[2,:,:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_geometry_xy_N=np.empty((3,64,64,chIn), float)\n",
    "#pre_data_xy_N=np.empty((3,64,64,3), float)\n",
    "#pre_data_xy_N[:,:,:,:]=data_xy1[:,:,:,:]\n",
    "#pre_geometry_xy_N[:,:,:,0:1]=geometry_xy1[:,:,:,0:1]\n",
    "#pre_geometry_xy_N[:,:,:,1:2]=geometry_xy1[:,:,:,:1:2]\n",
    "#pre_geometry_xy_N[:,:,:,2:3]=geometry_xy1[:,:,:,:5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(pre_geometry_xy, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_scale(sample_y, out_y,error, s):  \n",
    "           \n",
    "    minu = np.min(sample_y[s, :, :, 0])\n",
    "    maxu = np.max(sample_y[s, :, :, 0])\n",
    "    \n",
    "    minv = np.min(sample_y[s, :, :, 1])\n",
    "    maxv = np.max(sample_y[s, :, :, 1])\n",
    "    \n",
    "    #minp = np.min(sample_y[s, :, :, 2])\n",
    "    #maxp = np.max(sample_y[s, :, :, 2])\n",
    "    \n",
    "    minT = np.min(sample_y[s, :, :, 2])\n",
    "    maxT = np.max(sample_y[s, :, :, 2])\n",
    "    \n",
    "    #minp_rgh = np.min(sample_y[s, :, :, 4])\n",
    "    #maxp_rgh = np.max(sample_y[s, :, :, 4])\n",
    "    \n",
    "    mineu = np.min(error[s, 0, :, :])\n",
    "    maxeu = np.max(error[s, 0, :, :])\n",
    "   \n",
    "    minev = np.min(error[s, 1, :, :])\n",
    "    maxev = np.max(error[s, 1, :, :])\n",
    "    \n",
    "  #  minep = np.min(error[s, 2, :, :])\n",
    "   # maxep = np.max(error[s, 2, :, :])\n",
    "    \n",
    "    mineT = np.min(error[s, 2, :, :])\n",
    "    maxeT = np.max(error[s, 2, :, :])\n",
    "    \n",
    "   # minep_rgh = np.min(error[s, 4, :, :])\n",
    "  #  maxep_rgh = np.max(error[s, 4, :, :])\n",
    "   \n",
    "    plt.figure()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(9, 10)\n",
    "    plt.subplot(5, 3, 1)\n",
    "    plt.title('CFD', fontsize=18)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, 0]), cmap='jet', vmin = minu, vmax = maxu, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('Ux', fontsize=18)\n",
    "    plt.subplot(5, 3, 2)\n",
    "    plt.title('CNN', fontsize=18)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, 0]), cmap='jet', vmin = minu, vmax = maxu, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(5, 3, 3)\n",
    "    plt.title('Error', fontsize=18)\n",
    "    plt.imshow(np.transpose(error[s, :, :, 0]), cmap='jet', vmin = mineu, vmax = maxeu, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "\n",
    "    plt.subplot(5, 3, 4)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, 1]), cmap='jet', vmin = minv, vmax = maxv, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('Uy', fontsize=18)\n",
    "    plt.subplot(5, 3, 5)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, 1]), cmap='jet', vmin = minv, vmax = maxv, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(5, 3, 6)\n",
    "    plt.imshow(np.transpose(error[s, :, :, 1]), cmap='jet', vmin = minev, vmax = maxev, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')    \n",
    "    \n",
    "    plt.subplot(5, 3, 7)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, 2]), cmap='jet', vmin = minT, vmax = maxT, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('T', fontsize=18)\n",
    "    plt.subplot(5, 3, 8)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, 2]), cmap='jet', vmin = minT, vmax = maxT, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(5, 3, 9)\n",
    "    plt.imshow(np.transpose(error[s, :, :, 2]), cmap='jet', vmin = mineT, vmax = maxeT, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\"\n",
    "    plt.subplot(5, 3, 7)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, 2]), cmap='jet', vmin = minp, vmax = maxp, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('p', fontsize=18)\n",
    "    plt.subplot(5, 3, 8)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, 2]), cmap='jet', vmin = minp, vmax = maxp, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(5, 3, 9)\n",
    "    plt.imshow(np.transpose(error[s, :, :, 2]), cmap='jet', vmin = minep, vmax = maxep, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "    plt.subplot(5, 3, 13)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, 4]), cmap='jet', vmin = minp_rgh, vmax = maxp_rgh, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('p_rgh', fontsize=18)\n",
    "    plt.subplot(5, 3, 14)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, 4]), cmap='jet', vmin = minp_rgh, vmax = maxp_rgh, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(5, 3, 15)\n",
    "    plt.imshow(np.transpose(error[s, :, :, 4]), cmap='jet', vmin = minep_rgh, vmax = maxep_rgh, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=3\n",
    "error = abs(pre_data_xy[:10] - val_preds[:10])\n",
    "\n",
    "visualize_scale(pre_data_xy[:10], val_preds[:10], error[:10], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_channel_check(sample_y, out_y,error, s, index1,index2,index3):\n",
    "           \n",
    "    minu = 0\n",
    "    maxu = 1\n",
    "    \n",
    "    minv = 0\n",
    "    maxv = 1\n",
    "    \n",
    "    minp = 0\n",
    "    maxp = 1\n",
    "    \n",
    "    mineu = 0\n",
    "    maxeu = 1\n",
    "    \n",
    "    minev = 0\n",
    "    maxev = 0.2\n",
    "    \n",
    "    minep = 0\n",
    "    maxep = 0.2\n",
    "           \n",
    "    plt.figure()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15, 10)\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plt.title('CFD', fontsize=18)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, index1]), cmap='jet', vmin = minu, vmax = maxu, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('Ux', fontsize=18)\n",
    "    plt.subplot(3, 3, 2)\n",
    "    plt.title('CNN', fontsize=18)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, index1]), cmap='jet', vmin = minu, vmax = maxu, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(3, 3, 3)\n",
    "    plt.title('Error', fontsize=18)\n",
    "    plt.imshow(np.transpose(error[s, :, :, index1]), cmap='jet', vmin = mineu, vmax = maxeu, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "\n",
    "    plt.subplot(3, 3, 4)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, index2]), cmap='jet', vmin = minv, vmax = maxv, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('Uy', fontsize=18)\n",
    "    plt.subplot(3, 3, 5)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, index2]), cmap='jet', vmin = minv, vmax = maxv, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(3, 3, 6)\n",
    "    plt.imshow(np.transpose(error[s, :, :, index2]), cmap='jet', vmin = minev, vmax = maxev, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "\n",
    "    plt.subplot(3, 3, 7)\n",
    "    plt.imshow(np.transpose(sample_y[s, :, :, index3]), cmap='jet', vmin = minp, vmax = maxp, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.ylabel('p', fontsize=18)\n",
    "    plt.subplot(3, 3, 8)\n",
    "    plt.imshow(np.transpose(out_y[s, :, :, index3]), cmap='jet', vmin = minp, vmax = maxp, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.subplot(3, 3, 9)\n",
    "    plt.imshow(np.transpose(error[s, :, :, index3]), cmap='jet', vmin = minep, vmax = maxep, origin='lower', extent=[0,1,0,1])\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=55\n",
    "error = abs(geometry_xy[:152] - geometry_xy[:152])\n",
    "\n",
    "visualize_channel_check(geometry_xy[:152], geometry_xy[:152], error[:152], s, 3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
